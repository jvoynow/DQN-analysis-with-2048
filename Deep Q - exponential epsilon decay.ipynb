{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intitializeAgent():\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(256,activation='relu',input_shape=(INPUT_SIZE,)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(256,activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(256,activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(OUTPUT_SIZE,activation='linear'))\n",
    "    \n",
    "    model.compile(optimizer='adam',loss='mse',metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPrediction(env,agent):\n",
    "    env = env.reshape(INPUT_SIZE,1).reshape(1,-1)\n",
    "    return agent.predict(env)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAction(output,invalidActions):\n",
    "    rand = np.random.rand()\n",
    "    output[invalidActions] = np.min(output) - 0.1\n",
    "    \n",
    "    if rand < EPSILON_RATE ** iteration:\n",
    "        action = np.random.randint(4)\n",
    "        while action in invalidActions:\n",
    "            action = np.random.randint(4)\n",
    "        return action\n",
    "    else:\n",
    "        return np.argmax(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGreedyAction(output,invalidActions):\n",
    "    output[invalidActions] = np.min(output) - 0.1\n",
    "    return np.argmax(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(initialStateMemory,actionMemory,rewardMemory,finalStateMemory,model,epochs):\n",
    "    \n",
    "    if memCount < MAX_MEM_SIZE:\n",
    "        sample = np.random.choice(memCount, SAMPLE_SIZE)\n",
    "    else:\n",
    "        sample = np.random.choice(MAX_MEM_SIZE, SAMPLE_SIZE)\n",
    "    batchSize = sample.shape[0] // BATCH_SIZE\n",
    "    \n",
    "    if batchSize == 0:\n",
    "        batchSize = 1\n",
    "                \n",
    "    targetQs = getTargetQs(initialStateMemory[sample],\n",
    "                            actionMemory[sample],\n",
    "                            rewardMemory[sample],\n",
    "                            finalStateMemory[sample],\n",
    "                            model)\n",
    "        \n",
    "    print(\"Training Model...\")\n",
    "    model.fit(initialStateMemory[sample],targetQs,batch_size = batchSize, epochs = epochs, verbose = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replay Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addMemory(initialState, action, reward, finalState, memCount, MAX_MEM_SIZE):\n",
    "    if memCount < MAX_MEM_SIZE:\n",
    "        initialStateMemory[memCount] = initialState.reshape(INPUT_SIZE)\n",
    "        actionMemory[memCount] = action\n",
    "        rewardMemory[memCount] = reward\n",
    "        finalStateMemory[memCount] = finalState.reshape(INPUT_SIZE)\n",
    "    else:\n",
    "        rand = np.random.randint(MAX_MEM_SIZE)\n",
    "        initialStateMemory[rand] = initialState.reshape(INPUT_SIZE)\n",
    "        actionMemory[rand] = action\n",
    "        rewardMemory[rand] = reward\n",
    "        finalStateMemory[rand] = finalState.reshape(INPUT_SIZE)\n",
    "        \n",
    "    memCount += 1\n",
    "    \n",
    "    return initialStateMemory,actionMemory,rewardMemory,finalStateMemory,memCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTargetQs(states0, actions0, rewards1, states1, agent):\n",
    "    DISCOUNT_FACTOR = 0.99\n",
    "    targetQs = np.zeros((len(states0),OUTPUT_SIZE))\n",
    "    \n",
    "    for i in range(len(states0)):\n",
    "        targetQs[i] = getPrediction(states0[i],agent)\n",
    "        targetQs[i][int(actions0[i])] = rewards1[i] + DISCOUNT_FACTOR * np.max(getPrediction(states1[i],agent))\n",
    "    return targetQs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Game Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeEnv():\n",
    "    env = np.zeros((BOARD_LENGTH,BOARD_LENGTH))\n",
    "\n",
    "    for i in range(2):\n",
    "        addValue(env)\n",
    "            \n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addValue(env):\n",
    "#     rand = np.random.rand()\n",
    "#     if rand > 0.1:\n",
    "#         value = 2\n",
    "#     else:\n",
    "#         value = 4\n",
    "    value = 2\n",
    "        \n",
    "    coordinate1 = random.sample(range(0,BOARD_LENGTH),1)\n",
    "    coordinate2 = random.sample(range(0,BOARD_LENGTH),1)\n",
    "        \n",
    "    if env[coordinate1,coordinate2] != 0:\n",
    "        getNewCoordinate(env,value)\n",
    "    else:\n",
    "        env[coordinate1,coordinate2] = value\n",
    "        \n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNewCoordinate(env,value):\n",
    "    \n",
    "    coordinate1 = random.sample(range(0,BOARD_LENGTH),1)\n",
    "    coordinate2 = random.sample(range(0,BOARD_LENGTH),1)\n",
    "    \n",
    "    while env[coordinate1,coordinate2] != 0:\n",
    "        coordinate1 = random.sample(range(0,BOARD_LENGTH),1)\n",
    "        coordinate2 = random.sample(range(0,BOARD_LENGTH),1)\n",
    "    \n",
    "    env[coordinate1,coordinate2] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(env,action,score):\n",
    "    \n",
    "    if action == 0:\n",
    "        env, score, validAction = actionUp(env,score)\n",
    "    if action == 1:\n",
    "        env, score, validAction = actionDown(env,score)\n",
    "    if action == 2:\n",
    "        env, score, validAction = actionLeft(env,score)\n",
    "    if action == 3:\n",
    "        env, score, validAction = actionRight(env,score)\n",
    "    \n",
    "    return env, score, validAction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actionUp(env,score):\n",
    "    validAction = False\n",
    "    \n",
    "    for i in range(BOARD_LENGTH):\n",
    "        for j in range(BOARD_LENGTH):\n",
    "            row = i\n",
    "            while env[row][j] != 0 and row != 0:\n",
    "                if env[row - 1][j] != 0:\n",
    "                    if env[row - 1][j] == env[row][j]:\n",
    "                        env[row - 1][j] *= 2\n",
    "                        env[row][j] = 0\n",
    "                        score += env[row - 1][j]\n",
    "                        validAction = True\n",
    "                    break\n",
    "                temp = env[row][j]\n",
    "                env[row-1][j] = temp\n",
    "                env[row][j] = 0\n",
    "                row -= 1\n",
    "                validAction = True\n",
    "    return env, score, validAction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actionDown(env,score):\n",
    "    validAction = False\n",
    "    \n",
    "    for i in range(3,-1,-1):\n",
    "        for j in range(BOARD_LENGTH):\n",
    "            row = i\n",
    "            while env[row][j] != 0 and row != 3:\n",
    "                if env[row + 1][j] != 0:\n",
    "                    if env[row + 1][j] == env[row][j]:\n",
    "                        env[row + 1][j] *= 2\n",
    "                        env[row][j] = 0\n",
    "                        score += env[row + 1][j]\n",
    "                        validAction = True\n",
    "                    break\n",
    "                temp = env[row][j]\n",
    "                env[row + 1][j] = temp\n",
    "                env[row][j] = 0\n",
    "                row += 1\n",
    "                validAction = True\n",
    "    return env, score, validAction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actionLeft(env,score):\n",
    "    validAction = False\n",
    "    env = env.T\n",
    "    \n",
    "    for i in range(BOARD_LENGTH):\n",
    "        for j in range(BOARD_LENGTH):\n",
    "            row = i\n",
    "            while env[row][j] != 0 and row != 0:\n",
    "                if env[row - 1][j] != 0:\n",
    "                    if env[row - 1][j] == env[row][j]:\n",
    "                        env[row - 1][j] *= 2\n",
    "                        env[row][j] = 0\n",
    "                        score += env[row - 1][j]\n",
    "                        validAction = True\n",
    "                    break\n",
    "                temp = env[row][j]\n",
    "                env[row-1][j] = temp\n",
    "                env[row][j] = 0\n",
    "                row -= 1\n",
    "                validAction = True\n",
    "    env = env.T\n",
    "    return env, score, validAction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actionRight(env,score):\n",
    "    validAction = False\n",
    "    env = env.T\n",
    "    \n",
    "    for i in range(3,-1,-1):\n",
    "        for j in range(BOARD_LENGTH):\n",
    "            row = i\n",
    "            while env[row][j] != 0 and row != 3:\n",
    "                if env[row + 1][j] != 0:\n",
    "                    if env[row + 1][j] == env[row][j]:\n",
    "                        env[row + 1][j] *= 2\n",
    "                        env[row][j] = 0\n",
    "                        score += env[row + 1][j]\n",
    "                        validAction = True\n",
    "                    break\n",
    "                temp = env[row][j]\n",
    "                env[row + 1][j] = temp\n",
    "                env[row][j] = 0\n",
    "                row += 1\n",
    "                validAction = True\n",
    "    env = env.T\n",
    "    return env, score, validAction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAvailableAction(env):\n",
    "    tempEnv = np.copy(env)\n",
    "    available = False\n",
    "    \n",
    "    for i in range(tempEnv.shape[0]):\n",
    "        for j in range(tempEnv.shape[0] - 1):\n",
    "            if tempEnv[i][j] == tempEnv[i][j+1]:\n",
    "                available = True\n",
    "                \n",
    "                \n",
    "    tempEnv = tempEnv.T\n",
    "    for i in range(tempEnv.shape[0]):\n",
    "        for j in range(tempEnv.shape[0] - 1):\n",
    "            if tempEnv[i][j] == tempEnv[i][j+1]:\n",
    "                available = True\n",
    "                break\n",
    "    \n",
    "    return available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(env,agent,memCount,testFlag,score = 0):\n",
    "    \n",
    "    gameOver = False\n",
    "    while gameOver == False:\n",
    "        invalidActions = []\n",
    "        validAction = False\n",
    "        while validAction == False:\n",
    "            \n",
    "            if not testFlag:\n",
    "                previousEnv = np.copy(env)\n",
    "                previousScore = np.copy(score)\n",
    "            \n",
    "            output = getPrediction(env,agent)\n",
    "            if testFlag: \n",
    "                action = getGreedyAction(output,invalidActions) \n",
    "            else: \n",
    "                action = getAction(output,invalidActions)\n",
    "            invalidActions.append(action)\n",
    "            env, score, validAction = step(env, action, score)\n",
    "        \n",
    "        if not testFlag:\n",
    "            initialStateMemory,actionMemory,rewardMemory,finalStateMemory,memCount = addMemory(previousEnv, action, score - previousScore, env, memCount, MAX_MEM_SIZE)\n",
    "\n",
    "        env = addValue(env)\n",
    "        \n",
    "        if np.sum(env == 0) == 0:\n",
    "            gameOver = not getAvailableAction(env)\n",
    "    \n",
    "    if not testFlag:\n",
    "        return score,initialStateMemory,actionMemory,rewardMemory,finalStateMemory,memCount\n",
    "    else: \n",
    "        return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Output Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printIter():\n",
    "    print(\"\\n === === === Iteration\",iteration,\"of\",ITERATIONS,'=== === ===\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printStats(timeLog,iteration,ITERATIONS,memCount,scoreLog,greedyScoreLog,EPISODES,TESTS):\n",
    "    print(\"\\nEstimated time remaining: \", format(np.mean(timeLog) * (ITERATIONS - iteration) / 60,'.2f'),\" Minutes\\n\")\n",
    "    print(\"Memories Elapsed: \",memCount)\n",
    "    print(\"Current Epsilon: \",format(EPSILON_RATE ** iteration,'.4f'))\n",
    "    print(\"Ave Score for Epoch: \", format(np.mean(scoreLog[len(scoreLog) - EPISODES : len(scoreLog)-1]) ,'.2f'))\n",
    "    print(\"Ave Greedy Score for Epoch: \", format(np.mean(greedyScoreLog[len(greedyScoreLog) - TESTS : len(greedyScoreLog)-1]) ,'.2f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printTrainInfo():\n",
    "    print(\"Maximum memory size:\",MAX_MEM_SIZE)\n",
    "    print(\"Sample size for training:\",SAMPLE_SIZE)\n",
    "    print(\"Batch size from sample:\",BATCH_SIZE)\n",
    "    print(\"Epslon Rate:\",format(EPSILON_RATE,'.4f'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n",
    "import sys\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOARD_LENGTH = 4\n",
    "INPUT_SIZE = 16\n",
    "OUTPUT_SIZE = BOARD_LENGTH\n",
    "\n",
    "memCount = 0\n",
    "MAX_MEM_SIZE = 100_000\n",
    "SAMPLE_SIZE = MAX_MEM_SIZE // 200\n",
    "BATCH_SIZE = SAMPLE_SIZE // 100\n",
    "initialStateMemory = np.zeros((MAX_MEM_SIZE,INPUT_SIZE))\n",
    "actionMemory = np.zeros(MAX_MEM_SIZE)\n",
    "rewardMemory = np.zeros(MAX_MEM_SIZE)\n",
    "finalStateMemory = np.zeros((MAX_MEM_SIZE,INPUT_SIZE))\n",
    "\n",
    "\n",
    "gameScoreLog = []\n",
    "greedyScoreLog = []\n",
    "agent = intitializeAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITERATIONS = 100\n",
    "EPISODES = 100\n",
    "TESTS = EPISODES // 5\n",
    "EPOCHS = 4\n",
    "MIN_EPSILON = 0.05\n",
    "EPSILON_RATE = MIN_EPSILON ** (1./ITERATIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum memory size: 100000\n",
      "Sample size for training: 500\n",
      "Batch size from sample: 5\n",
      "Epslon Rate: 0.9705\n",
      "\n",
      " === === === Iteration 0 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  20.04  Minutes\n",
      "\n",
      "Memories Elapsed:  13210\n",
      "Current Epsilon:  1.0000\n",
      "Ave Score for Epoch:  1185.37\n",
      "Ave Greedy Score for Epoch:  2382.95\n",
      "\n",
      " === === === Iteration 1 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  5.27  Minutes\n",
      "\n",
      "Memories Elapsed:  16631\n",
      "Current Epsilon:  0.9705\n",
      "Ave Score for Epoch:  1204.00\n",
      "Ave Greedy Score for Epoch:  1720.00\n",
      "\n",
      " === === === Iteration 2 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  5.14  Minutes\n",
      "\n",
      "Memories Elapsed:  20153\n",
      "Current Epsilon:  0.9418\n",
      "Ave Score for Epoch:  1271.00\n",
      "Ave Greedy Score for Epoch:  1320.00\n",
      "\n",
      " === === === Iteration 3 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  5.00  Minutes\n",
      "\n",
      "Memories Elapsed:  23361\n",
      "Current Epsilon:  0.9140\n",
      "Ave Score for Epoch:  1132.33\n",
      "Ave Greedy Score for Epoch:  1578.00\n",
      "\n",
      " === === === Iteration 4 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  4.94  Minutes\n",
      "\n",
      "Memories Elapsed:  26973\n",
      "Current Epsilon:  0.8871\n",
      "Ave Score for Epoch:  1360.33\n",
      "Ave Greedy Score for Epoch:  1166.00\n",
      "\n",
      " === === === Iteration 5 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  4.81  Minutes\n",
      "\n",
      "Memories Elapsed:  30327\n",
      "Current Epsilon:  0.8609\n",
      "Ave Score for Epoch:  1247.17\n",
      "Ave Greedy Score for Epoch:  997.00\n",
      "\n",
      " === === === Iteration 6 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  4.78  Minutes\n",
      "\n",
      "Memories Elapsed:  33826\n",
      "Current Epsilon:  0.8355\n",
      "Ave Score for Epoch:  1294.50\n",
      "Ave Greedy Score for Epoch:  1842.00\n",
      "\n",
      " === === === Iteration 7 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  4.69  Minutes\n",
      "\n",
      "Memories Elapsed:  37188\n",
      "Current Epsilon:  0.8108\n",
      "Ave Score for Epoch:  1177.67\n",
      "Ave Greedy Score for Epoch:  1108.00\n",
      "\n",
      " === === === Iteration 8 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  4.58  Minutes\n",
      "\n",
      "Memories Elapsed:  40336\n",
      "Current Epsilon:  0.7869\n",
      "Ave Score for Epoch:  1100.33\n",
      "Ave Greedy Score for Epoch:  1134.00\n",
      "\n",
      " === === === Iteration 9 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  4.59  Minutes\n",
      "\n",
      "Memories Elapsed:  44161\n",
      "Current Epsilon:  0.7637\n",
      "Ave Score for Epoch:  1461.67\n",
      "Ave Greedy Score for Epoch:  1041.00\n",
      "\n",
      " === === === Iteration 10 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  4.53  Minutes\n",
      "\n",
      "Memories Elapsed:  47663\n",
      "Current Epsilon:  0.7411\n",
      "Ave Score for Epoch:  1245.50\n",
      "Ave Greedy Score for Epoch:  949.00\n",
      "\n",
      " === === === Iteration 11 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  4.51  Minutes\n",
      "\n",
      "Memories Elapsed:  51317\n",
      "Current Epsilon:  0.7193\n",
      "Ave Score for Epoch:  1320.17\n",
      "Ave Greedy Score for Epoch:  1775.00\n",
      "\n",
      " === === === Iteration 12 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  4.48  Minutes\n",
      "\n",
      "Memories Elapsed:  54822\n",
      "Current Epsilon:  0.6980\n",
      "Ave Score for Epoch:  1232.83\n",
      "Ave Greedy Score for Epoch:  1800.00\n",
      "\n",
      " === === === Iteration 13 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  4.45  Minutes\n",
      "\n",
      "Memories Elapsed:  58244\n",
      "Current Epsilon:  0.6774\n",
      "Ave Score for Epoch:  1215.50\n",
      "Ave Greedy Score for Epoch:  2525.00\n",
      "\n",
      " === === === Iteration 14 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  4.44  Minutes\n",
      "\n",
      "Memories Elapsed:  61581\n",
      "Current Epsilon:  0.6574\n",
      "Ave Score for Epoch:  1171.17\n",
      "Ave Greedy Score for Epoch:  1849.00\n",
      "\n",
      " === === === Iteration 15 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  4.39  Minutes\n",
      "\n",
      "Memories Elapsed:  64987\n",
      "Current Epsilon:  0.6380\n",
      "Ave Score for Epoch:  1195.83\n",
      "Ave Greedy Score for Epoch:  865.00\n",
      "\n",
      " === === === Iteration 16 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  4.38  Minutes\n",
      "\n",
      "Memories Elapsed:  68593\n",
      "Current Epsilon:  0.6192\n",
      "Ave Score for Epoch:  1323.83\n",
      "Ave Greedy Score for Epoch:  2075.00\n",
      "\n",
      " === === === Iteration 17 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  4.34  Minutes\n",
      "\n",
      "Memories Elapsed:  72133\n",
      "Current Epsilon:  0.6009\n",
      "Ave Score for Epoch:  1309.67\n",
      "Ave Greedy Score for Epoch:  1157.00\n",
      "\n",
      " === === === Iteration 18 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  4.27  Minutes\n",
      "\n",
      "Memories Elapsed:  75483\n",
      "Current Epsilon:  0.5832\n",
      "Ave Score for Epoch:  1177.33\n",
      "Ave Greedy Score for Epoch:  1330.00\n",
      "\n",
      " === === === Iteration 19 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  4.24  Minutes\n",
      "\n",
      "Memories Elapsed:  79311\n",
      "Current Epsilon:  0.5660\n",
      "Ave Score for Epoch:  1423.00\n",
      "Ave Greedy Score for Epoch:  2122.00\n",
      "\n",
      " === === === Iteration 20 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  4.19  Minutes\n",
      "\n",
      "Memories Elapsed:  82815\n",
      "Current Epsilon:  0.5493\n",
      "Ave Score for Epoch:  1291.00\n",
      "Ave Greedy Score for Epoch:  1736.00\n",
      "\n",
      " === === === Iteration 21 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  4.14  Minutes\n",
      "\n",
      "Memories Elapsed:  86155\n",
      "Current Epsilon:  0.5331\n",
      "Ave Score for Epoch:  1196.00\n",
      "Ave Greedy Score for Epoch:  2384.00\n",
      "\n",
      " === === === Iteration 22 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  4.07  Minutes\n",
      "\n",
      "Memories Elapsed:  89378\n",
      "Current Epsilon:  0.5173\n",
      "Ave Score for Epoch:  1117.83\n",
      "Ave Greedy Score for Epoch:  1318.00\n",
      "\n",
      " === === === Iteration 23 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  4.05  Minutes\n",
      "\n",
      "Memories Elapsed:  93518\n",
      "Current Epsilon:  0.5021\n",
      "Ave Score for Epoch:  1627.83\n",
      "Ave Greedy Score for Epoch:  1423.00\n",
      "\n",
      " === === === Iteration 24 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  4.01  Minutes\n",
      "\n",
      "Memories Elapsed:  97321\n",
      "Current Epsilon:  0.4873\n",
      "Ave Score for Epoch:  1394.17\n",
      "Ave Greedy Score for Epoch:  1379.00\n",
      "\n",
      " === === === Iteration 25 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  3.95  Minutes\n",
      "\n",
      "Memories Elapsed:  100462\n",
      "Current Epsilon:  0.4729\n",
      "Ave Score for Epoch:  1061.00\n",
      "Ave Greedy Score for Epoch:  1410.00\n",
      "\n",
      " === === === Iteration 26 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  3.89  Minutes\n",
      "\n",
      "Memories Elapsed:  103740\n",
      "Current Epsilon:  0.4589\n",
      "Ave Score for Epoch:  1117.83\n",
      "Ave Greedy Score for Epoch:  1251.00\n",
      "\n",
      " === === === Iteration 27 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  3.84  Minutes\n",
      "\n",
      "Memories Elapsed:  107160\n",
      "Current Epsilon:  0.4454\n",
      "Ave Score for Epoch:  1208.67\n",
      "Ave Greedy Score for Epoch:  1791.00\n",
      "\n",
      " === === === Iteration 28 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  3.79  Minutes\n",
      "\n",
      "Memories Elapsed:  110886\n",
      "Current Epsilon:  0.4322\n",
      "Ave Score for Epoch:  1350.50\n",
      "Ave Greedy Score for Epoch:  1073.00\n",
      "\n",
      " === === === Iteration 29 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  3.74  Minutes\n",
      "\n",
      "Memories Elapsed:  114445\n",
      "Current Epsilon:  0.4195\n",
      "Ave Score for Epoch:  1291.50\n",
      "Ave Greedy Score for Epoch:  1104.00\n",
      "\n",
      " === === === Iteration 30 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  3.68  Minutes\n",
      "\n",
      "Memories Elapsed:  117787\n",
      "Current Epsilon:  0.4071\n",
      "Ave Score for Epoch:  1159.67\n",
      "Ave Greedy Score for Epoch:  1223.00\n",
      "\n",
      " === === === Iteration 31 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  3.63  Minutes\n",
      "\n",
      "Memories Elapsed:  121437\n",
      "Current Epsilon:  0.3951\n",
      "Ave Score for Epoch:  1344.17\n",
      "Ave Greedy Score for Epoch:  931.00\n",
      "\n",
      " === === === Iteration 32 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  3.58  Minutes\n",
      "\n",
      "Memories Elapsed:  124971\n",
      "Current Epsilon:  0.3834\n",
      "Ave Score for Epoch:  1270.83\n",
      "Ave Greedy Score for Epoch:  1578.00\n",
      "\n",
      " === === === Iteration 33 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  3.54  Minutes\n",
      "\n",
      "Memories Elapsed:  128436\n",
      "Current Epsilon:  0.3721\n",
      "Ave Score for Epoch:  1254.50\n",
      "Ave Greedy Score for Epoch:  2117.00\n",
      "\n",
      " === === === Iteration 34 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  3.49  Minutes\n",
      "\n",
      "Memories Elapsed:  131871\n",
      "Current Epsilon:  0.3611\n",
      "Ave Score for Epoch:  1192.50\n",
      "Ave Greedy Score for Epoch:  2004.00\n",
      "\n",
      " === === === Iteration 35 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  3.44  Minutes\n",
      "\n",
      "Memories Elapsed:  135450\n",
      "Current Epsilon:  0.3505\n",
      "Ave Score for Epoch:  1265.67\n",
      "Ave Greedy Score for Epoch:  2406.00\n",
      "\n",
      " === === === Iteration 36 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  3.38  Minutes\n",
      "\n",
      "Memories Elapsed:  138789\n",
      "Current Epsilon:  0.3401\n",
      "Ave Score for Epoch:  1147.67\n",
      "Ave Greedy Score for Epoch:  1108.00\n",
      "\n",
      " === === === Iteration 37 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  3.33  Minutes\n",
      "\n",
      "Memories Elapsed:  142264\n",
      "Current Epsilon:  0.3301\n",
      "Ave Score for Epoch:  1237.00\n",
      "Ave Greedy Score for Epoch:  1491.00\n",
      "\n",
      " === === === Iteration 38 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  3.28  Minutes\n",
      "\n",
      "Memories Elapsed:  145713\n",
      "Current Epsilon:  0.3203\n",
      "Ave Score for Epoch:  1220.17\n",
      "Ave Greedy Score for Epoch:  2200.00\n",
      "\n",
      " === === === Iteration 39 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  3.24  Minutes\n",
      "\n",
      "Memories Elapsed:  149454\n",
      "Current Epsilon:  0.3109\n",
      "Ave Score for Epoch:  1380.67\n",
      "Ave Greedy Score for Epoch:  1758.00\n",
      "\n",
      " === === === Iteration 40 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  3.19  Minutes\n",
      "\n",
      "Memories Elapsed:  153113\n",
      "Current Epsilon:  0.3017\n",
      "Ave Score for Epoch:  1247.83\n",
      "Ave Greedy Score for Epoch:  3029.00\n",
      "\n",
      " === === === Iteration 41 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  3.16  Minutes\n",
      "\n",
      "Memories Elapsed:  157095\n",
      "Current Epsilon:  0.2928\n",
      "Ave Score for Epoch:  1554.83\n",
      "Ave Greedy Score for Epoch:  2296.00\n",
      "\n",
      " === === === Iteration 42 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  3.11  Minutes\n",
      "\n",
      "Memories Elapsed:  160766\n",
      "Current Epsilon:  0.2842\n",
      "Ave Score for Epoch:  1306.33\n",
      "Ave Greedy Score for Epoch:  3239.00\n",
      "\n",
      " === === === Iteration 43 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  3.09  Minutes\n",
      "\n",
      "Memories Elapsed:  165103\n",
      "Current Epsilon:  0.2758\n",
      "Ave Score for Epoch:  1601.50\n",
      "Ave Greedy Score for Epoch:  3654.00\n",
      "\n",
      " === === === Iteration 44 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  3.05  Minutes\n",
      "\n",
      "Memories Elapsed:  169017\n",
      "Current Epsilon:  0.2676\n",
      "Ave Score for Epoch:  1470.67\n",
      "Ave Greedy Score for Epoch:  2781.00\n",
      "\n",
      " === === === Iteration 45 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  2.99  Minutes\n",
      "\n",
      "Memories Elapsed:  172540\n",
      "Current Epsilon:  0.2597\n",
      "Ave Score for Epoch:  1293.17\n",
      "Ave Greedy Score for Epoch:  1574.00\n",
      "\n",
      " === === === Iteration 46 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  2.94  Minutes\n",
      "\n",
      "Memories Elapsed:  176122\n",
      "Current Epsilon:  0.2521\n",
      "Ave Score for Epoch:  1275.83\n",
      "Ave Greedy Score for Epoch:  2206.00\n",
      "\n",
      " === === === Iteration 47 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  2.90  Minutes\n",
      "\n",
      "Memories Elapsed:  180586\n",
      "Current Epsilon:  0.2446\n",
      "Ave Score for Epoch:  1779.67\n",
      "Ave Greedy Score for Epoch:  2638.00\n",
      "\n",
      " === === === Iteration 48 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  2.86  Minutes\n",
      "\n",
      "Memories Elapsed:  184539\n",
      "Current Epsilon:  0.2374\n",
      "Ave Score for Epoch:  1484.50\n",
      "Ave Greedy Score for Epoch:  2350.00\n",
      "\n",
      " === === === Iteration 49 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  2.81  Minutes\n",
      "\n",
      "Memories Elapsed:  188468\n",
      "Current Epsilon:  0.2304\n",
      "Ave Score for Epoch:  1450.83\n",
      "Ave Greedy Score for Epoch:  3235.00\n",
      "\n",
      " === === === Iteration 50 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  2.77  Minutes\n",
      "\n",
      "Memories Elapsed:  192687\n",
      "Current Epsilon:  0.2236\n",
      "Ave Score for Epoch:  1590.00\n",
      "Ave Greedy Score for Epoch:  3178.00\n",
      "\n",
      " === === === Iteration 51 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  2.73  Minutes\n",
      "\n",
      "Memories Elapsed:  196914\n",
      "Current Epsilon:  0.2170\n",
      "Ave Score for Epoch:  1643.17\n",
      "Ave Greedy Score for Epoch:  2323.00\n",
      "\n",
      " === === === Iteration 52 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  2.68  Minutes\n",
      "\n",
      "Memories Elapsed:  201064\n",
      "Current Epsilon:  0.2106\n",
      "Ave Score for Epoch:  1556.00\n",
      "Ave Greedy Score for Epoch:  1896.00\n",
      "\n",
      " === === === Iteration 53 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  2.63  Minutes\n",
      "\n",
      "Memories Elapsed:  205070\n",
      "Current Epsilon:  0.2044\n",
      "Ave Score for Epoch:  1481.00\n",
      "Ave Greedy Score for Epoch:  2877.00\n",
      "\n",
      " === === === Iteration 54 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  2.58  Minutes\n",
      "\n",
      "Memories Elapsed:  209504\n",
      "Current Epsilon:  0.1984\n",
      "Ave Score for Epoch:  1708.17\n",
      "Ave Greedy Score for Epoch:  2792.00\n",
      "\n",
      " === === === Iteration 55 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  2.54  Minutes\n",
      "\n",
      "Memories Elapsed:  213688\n",
      "Current Epsilon:  0.1925\n",
      "Ave Score for Epoch:  1598.83\n",
      "Ave Greedy Score for Epoch:  3371.00\n",
      "\n",
      " === === === Iteration 56 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  2.49  Minutes\n",
      "\n",
      "Memories Elapsed:  217917\n",
      "Current Epsilon:  0.1868\n",
      "Ave Score for Epoch:  1617.00\n",
      "Ave Greedy Score for Epoch:  3508.00\n",
      "\n",
      " === === === Iteration 57 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  2.44  Minutes\n",
      "\n",
      "Memories Elapsed:  222078\n",
      "Current Epsilon:  0.1813\n",
      "Ave Score for Epoch:  1610.00\n",
      "Ave Greedy Score for Epoch:  3405.00\n",
      "\n",
      " === === === Iteration 58 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  2.40  Minutes\n",
      "\n",
      "Memories Elapsed:  226423\n",
      "Current Epsilon:  0.1760\n",
      "Ave Score for Epoch:  1706.17\n",
      "Ave Greedy Score for Epoch:  3062.00\n",
      "\n",
      " === === === Iteration 59 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  2.35  Minutes\n",
      "\n",
      "Memories Elapsed:  231090\n",
      "Current Epsilon:  0.1708\n",
      "Ave Score for Epoch:  1809.17\n",
      "Ave Greedy Score for Epoch:  2761.00\n",
      "\n",
      " === === === Iteration 60 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  2.30  Minutes\n",
      "\n",
      "Memories Elapsed:  235681\n",
      "Current Epsilon:  0.1657\n",
      "Ave Score for Epoch:  1802.17\n",
      "Ave Greedy Score for Epoch:  1923.00\n",
      "\n",
      " === === === Iteration 61 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  2.25  Minutes\n",
      "\n",
      "Memories Elapsed:  239699\n",
      "Current Epsilon:  0.1608\n",
      "Ave Score for Epoch:  1425.33\n",
      "Ave Greedy Score for Epoch:  2554.00\n",
      "\n",
      " === === === Iteration 62 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  2.20  Minutes\n",
      "\n",
      "Memories Elapsed:  244111\n",
      "Current Epsilon:  0.1561\n",
      "Ave Score for Epoch:  1684.67\n",
      "Ave Greedy Score for Epoch:  2934.00\n",
      "\n",
      " === === === Iteration 63 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  2.15  Minutes\n",
      "\n",
      "Memories Elapsed:  248508\n",
      "Current Epsilon:  0.1515\n",
      "Ave Score for Epoch:  1646.17\n",
      "Ave Greedy Score for Epoch:  2514.00\n",
      "\n",
      " === === === Iteration 64 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  2.10  Minutes\n",
      "\n",
      "Memories Elapsed:  252783\n",
      "Current Epsilon:  0.1470\n",
      "Ave Score for Epoch:  1614.83\n",
      "Ave Greedy Score for Epoch:  2607.00\n",
      "\n",
      " === === === Iteration 65 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  2.05  Minutes\n",
      "\n",
      "Memories Elapsed:  257019\n",
      "Current Epsilon:  0.1427\n",
      "Ave Score for Epoch:  1572.67\n",
      "Ave Greedy Score for Epoch:  2563.00\n",
      "\n",
      " === === === Iteration 66 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  2.00  Minutes\n",
      "\n",
      "Memories Elapsed:  261158\n",
      "Current Epsilon:  0.1385\n",
      "Ave Score for Epoch:  1630.83\n",
      "Ave Greedy Score for Epoch:  2587.00\n",
      "\n",
      " === === === Iteration 67 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  1.95  Minutes\n",
      "\n",
      "Memories Elapsed:  265804\n",
      "Current Epsilon:  0.1344\n",
      "Ave Score for Epoch:  1813.83\n",
      "Ave Greedy Score for Epoch:  3047.00\n",
      "\n",
      " === === === Iteration 68 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  1.89  Minutes\n",
      "\n",
      "Memories Elapsed:  270213\n",
      "Current Epsilon:  0.1304\n",
      "Ave Score for Epoch:  1720.83\n",
      "Ave Greedy Score for Epoch:  2241.00\n",
      "\n",
      " === === === Iteration 69 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  1.84  Minutes\n",
      "\n",
      "Memories Elapsed:  274796\n",
      "Current Epsilon:  0.1266\n",
      "Ave Score for Epoch:  1783.17\n",
      "Ave Greedy Score for Epoch:  2809.00\n",
      "\n",
      " === === === Iteration 70 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  1.79  Minutes\n",
      "\n",
      "Memories Elapsed:  280068\n",
      "Current Epsilon:  0.1228\n",
      "Ave Score for Epoch:  2212.17\n",
      "Ave Greedy Score for Epoch:  2084.00\n",
      "\n",
      " === === === Iteration 71 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  1.74  Minutes\n",
      "\n",
      "Memories Elapsed:  285065\n",
      "Current Epsilon:  0.1192\n",
      "Ave Score for Epoch:  2087.67\n",
      "Ave Greedy Score for Epoch:  2782.00\n",
      "\n",
      " === === === Iteration 72 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  1.68  Minutes\n",
      "\n",
      "Memories Elapsed:  289996\n",
      "Current Epsilon:  0.1157\n",
      "Ave Score for Epoch:  2050.83\n",
      "Ave Greedy Score for Epoch:  2089.00\n",
      "\n",
      " === === === Iteration 73 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  1.63  Minutes\n",
      "\n",
      "Memories Elapsed:  295002\n",
      "Current Epsilon:  0.1123\n",
      "Ave Score for Epoch:  1972.00\n",
      "Ave Greedy Score for Epoch:  2604.00\n",
      "\n",
      " === === === Iteration 74 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  1.57  Minutes\n",
      "\n",
      "Memories Elapsed:  299814\n",
      "Current Epsilon:  0.1090\n",
      "Ave Score for Epoch:  1860.50\n",
      "Ave Greedy Score for Epoch:  1696.00\n",
      "\n",
      " === === === Iteration 75 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  1.51  Minutes\n",
      "\n",
      "Memories Elapsed:  304286\n",
      "Current Epsilon:  0.1057\n",
      "Ave Score for Epoch:  1679.00\n",
      "Ave Greedy Score for Epoch:  2759.00\n",
      "\n",
      " === === === Iteration 76 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  1.46  Minutes\n",
      "\n",
      "Memories Elapsed:  309409\n",
      "Current Epsilon:  0.1026\n",
      "Ave Score for Epoch:  2090.33\n",
      "Ave Greedy Score for Epoch:  2259.00\n",
      "\n",
      " === === === Iteration 77 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  1.40  Minutes\n",
      "\n",
      "Memories Elapsed:  314370\n",
      "Current Epsilon:  0.0996\n",
      "Ave Score for Epoch:  2080.33\n",
      "Ave Greedy Score for Epoch:  2113.00\n",
      "\n",
      " === === === Iteration 78 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  1.34  Minutes\n",
      "\n",
      "Memories Elapsed:  319653\n",
      "Current Epsilon:  0.0966\n",
      "Ave Score for Epoch:  2183.00\n",
      "Ave Greedy Score for Epoch:  1867.00\n",
      "\n",
      " === === === Iteration 79 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  1.29  Minutes\n",
      "\n",
      "Memories Elapsed:  324561\n",
      "Current Epsilon:  0.0938\n",
      "Ave Score for Epoch:  1954.83\n",
      "Ave Greedy Score for Epoch:  2527.00\n",
      "\n",
      " === === === Iteration 80 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  1.23  Minutes\n",
      "\n",
      "Memories Elapsed:  329276\n",
      "Current Epsilon:  0.0910\n",
      "Ave Score for Epoch:  1827.00\n",
      "Ave Greedy Score for Epoch:  2468.00\n",
      "\n",
      " === === === Iteration 81 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  1.17  Minutes\n",
      "\n",
      "Memories Elapsed:  334601\n",
      "Current Epsilon:  0.0883\n",
      "Ave Score for Epoch:  2171.83\n",
      "Ave Greedy Score for Epoch:  2966.00\n",
      "\n",
      " === === === Iteration 82 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  1.11  Minutes\n",
      "\n",
      "Memories Elapsed:  339471\n",
      "Current Epsilon:  0.0857\n",
      "Ave Score for Epoch:  1831.50\n",
      "Ave Greedy Score for Epoch:  1950.00\n",
      "\n",
      " === === === Iteration 83 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  1.05  Minutes\n",
      "\n",
      "Memories Elapsed:  343557\n",
      "Current Epsilon:  0.0832\n",
      "Ave Score for Epoch:  1511.50\n",
      "Ave Greedy Score for Epoch:  3149.00\n",
      "\n",
      " === === === Iteration 84 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  0.99  Minutes\n",
      "\n",
      "Memories Elapsed:  348552\n",
      "Current Epsilon:  0.0807\n",
      "Ave Score for Epoch:  2008.50\n",
      "Ave Greedy Score for Epoch:  2779.00\n",
      "\n",
      " === === === Iteration 85 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  0.93  Minutes\n",
      "\n",
      "Memories Elapsed:  353199\n",
      "Current Epsilon:  0.0784\n",
      "Ave Score for Epoch:  1729.33\n",
      "Ave Greedy Score for Epoch:  2506.00\n",
      "\n",
      " === === === Iteration 86 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  0.87  Minutes\n",
      "\n",
      "Memories Elapsed:  358435\n",
      "Current Epsilon:  0.0761\n",
      "Ave Score for Epoch:  2129.00\n",
      "Ave Greedy Score for Epoch:  2568.00\n",
      "\n",
      " === === === Iteration 87 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  0.81  Minutes\n",
      "\n",
      "Memories Elapsed:  363260\n",
      "Current Epsilon:  0.0738\n",
      "Ave Score for Epoch:  1886.00\n",
      "Ave Greedy Score for Epoch:  3435.00\n",
      "\n",
      " === === === Iteration 88 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  0.75  Minutes\n",
      "\n",
      "Memories Elapsed:  368254\n",
      "Current Epsilon:  0.0716\n",
      "Ave Score for Epoch:  2005.83\n",
      "Ave Greedy Score for Epoch:  3964.00\n",
      "\n",
      " === === === Iteration 89 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  0.69  Minutes\n",
      "\n",
      "Memories Elapsed:  373207\n",
      "Current Epsilon:  0.0695\n",
      "Ave Score for Epoch:  2014.33\n",
      "Ave Greedy Score for Epoch:  2061.00\n",
      "\n",
      " === === === Iteration 90 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  0.63  Minutes\n",
      "\n",
      "Memories Elapsed:  378606\n",
      "Current Epsilon:  0.0675\n",
      "Ave Score for Epoch:  2256.33\n",
      "Ave Greedy Score for Epoch:  2251.00\n",
      "\n",
      " === === === Iteration 91 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  0.57  Minutes\n",
      "\n",
      "Memories Elapsed:  383805\n",
      "Current Epsilon:  0.0655\n",
      "Ave Score for Epoch:  2187.00\n",
      "Ave Greedy Score for Epoch:  2947.00\n",
      "\n",
      " === === === Iteration 92 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  0.51  Minutes\n",
      "\n",
      "Memories Elapsed:  389219\n",
      "Current Epsilon:  0.0635\n",
      "Ave Score for Epoch:  2223.00\n",
      "Ave Greedy Score for Epoch:  1812.00\n",
      "\n",
      " === === === Iteration 93 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  0.44  Minutes\n",
      "\n",
      "Memories Elapsed:  394308\n",
      "Current Epsilon:  0.0617\n",
      "Ave Score for Epoch:  1995.50\n",
      "Ave Greedy Score for Epoch:  2032.00\n",
      "\n",
      " === === === Iteration 94 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  0.38  Minutes\n",
      "\n",
      "Memories Elapsed:  399458\n",
      "Current Epsilon:  0.0598\n",
      "Ave Score for Epoch:  2047.17\n",
      "Ave Greedy Score for Epoch:  2391.00\n",
      "\n",
      " === === === Iteration 95 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  0.32  Minutes\n",
      "\n",
      "Memories Elapsed:  404007\n",
      "Current Epsilon:  0.0581\n",
      "Ave Score for Epoch:  1782.83\n",
      "Ave Greedy Score for Epoch:  1767.00\n",
      "\n",
      " === === === Iteration 96 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  0.26  Minutes\n",
      "\n",
      "Memories Elapsed:  409296\n",
      "Current Epsilon:  0.0564\n",
      "Ave Score for Epoch:  2087.50\n",
      "Ave Greedy Score for Epoch:  3167.00\n",
      "\n",
      " === === === Iteration 97 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  0.19  Minutes\n",
      "\n",
      "Memories Elapsed:  414727\n",
      "Current Epsilon:  0.0547\n",
      "Ave Score for Epoch:  2245.17\n",
      "Ave Greedy Score for Epoch:  2533.00\n",
      "\n",
      " === === === Iteration 98 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  0.13  Minutes\n",
      "\n",
      "Memories Elapsed:  419334\n",
      "Current Epsilon:  0.0531\n",
      "Ave Score for Epoch:  1789.83\n",
      "Ave Greedy Score for Epoch:  2654.00\n",
      "\n",
      " === === === Iteration 99 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  0.06  Minutes\n",
      "\n",
      "Memories Elapsed:  425641\n",
      "Current Epsilon:  0.0515\n",
      "Ave Score for Epoch:  2738.50\n",
      "Ave Greedy Score for Epoch:  2851.00\n"
     ]
    }
   ],
   "source": [
    "startTime = time.time()\n",
    "timeLog = []\n",
    "    \n",
    "printTrainInfo()\n",
    "\n",
    "for iteration in range(ITERATIONS):\n",
    "    printIter()\n",
    "    iterationStart = time.time()\n",
    "    \n",
    "    for i in range(EPISODES):\n",
    "\n",
    "        score,initialStateMemory,actionMemory,rewardMemory,finalStateMemory,memCount = run(initializeEnv(),agent,memCount,False)\n",
    "        gameScoreLog.append(score)\n",
    "    \n",
    "    for i in range(TESTS):\n",
    "        \n",
    "        score = run(initializeEnv(),agent,memCount,True)\n",
    "        greedyScoreLog.append(score)\n",
    "        \n",
    "    train(initialStateMemory,actionMemory,rewardMemory,finalStateMemory,agent,EPOCHS)\n",
    "    timeLog.append(time.time() - iterationStart)\n",
    "\n",
    "    printStats(timeLog,iteration,ITERATIONS,memCount,gameScoreLog,greedyScoreLog,EPISODES,TESTS)\n",
    "    \n",
    "    if EPISODES != 25:\n",
    "        startTime = time.time()\n",
    "        timeLog = []\n",
    "        gameScoreLog = []\n",
    "        greedyScoreLog = []\n",
    "    \n",
    "    EPISODES = 25\n",
    "    TESTS = EPISODES // 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def getMovingAve(movingAveSize, scores):\n",
    "    movingAve = []\n",
    "    \n",
    "    for i in range(len(scores) // movingAveSize):\n",
    "        if (i + 1) * movingAveSize < len(scores):\n",
    "            movingAve.append(np.mean(scores[i*movingAveSize:(i+1)*movingAveSize]))\n",
    "    return movingAve\n",
    "\n",
    "\n",
    "def mapScores():\n",
    "    movingAveSize = 5\n",
    "    \n",
    "    movingAveA = getMovingAve(movingAveSize * 5, gameScoreLog)\n",
    "    movingAveB = getMovingAve(movingAveSize, greedyScoreLog)\n",
    "    \n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.scatter(np.arange(len(movingAveA)),movingAveA)\n",
    "    plt.scatter(np.arange(len(movingAveB)),movingAveB)\n",
    "    \n",
    "mapScores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score:  2539.712\n",
      "Std Deviation:  1213.13\n",
      "Time elapsed:   472.13\n"
     ]
    }
   ],
   "source": [
    "def testAgent():\n",
    "    games = 500\n",
    "    \n",
    "    scores = np.zeros(games)\n",
    "    \n",
    "    for i in range(games):\n",
    "        scores[i] = (run(initializeEnv(),agent,memCount,True))\n",
    "    \n",
    "    print(\"Average Score: \", np.mean(scores))\n",
    "    print(\"Std Deviation: \", format(np.std(scores),'.2f'))\n",
    "    print(\"Time elapsed:  \", format(time.time() - startTime, '.2f'))\n",
    "    \n",
    "\n",
    "testAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
