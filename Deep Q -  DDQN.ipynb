{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intitializeAgent():\n",
    "    \n",
    "    model = Sequential() \n",
    "    \n",
    "    model.add(Dense(256,activation='relu',input_shape=(INPUT_SIZE,)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(256,activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(256,activation='relu'))\n",
    "    model.add(Dense(OUTPUT_SIZE,activation='linear'))\n",
    "    \n",
    "    model.compile(optimizer='adam',loss='mse',metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateTargetNetwork():\n",
    "    target.set_weights(agent.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPrediction(env,agent):\n",
    "    env = env.reshape(INPUT_SIZE,1).reshape(1,-1)\n",
    "    return agent.predict(env)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAction(output,invalidActions):\n",
    "    rand = np.random.rand()\n",
    "    output[invalidActions] = np.min(output) - 0.1\n",
    "    \n",
    "    if rand < 1 - EPSILON_RATE * iteration:\n",
    "        action = np.random.randint(4)\n",
    "        while action in invalidActions:\n",
    "            action = np.random.randint(4)\n",
    "        return action\n",
    "    else:\n",
    "        return np.argmax(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGreedyAction(output,invalidActions):\n",
    "    output[invalidActions] = np.min(output) - 0.1\n",
    "    return np.argmax(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(initialStateMemory,actionMemory,rewardMemory,finalStateMemory,evalnet,targetnet,epochs):\n",
    "    \n",
    "    if memCount < MAX_MEM_SIZE:\n",
    "        s = np.random.choice(memCount, SAMPLE_SIZE)\n",
    "    else:\n",
    "        s = np.random.choice(MAX_MEM_SIZE, SAMPLE_SIZE)\n",
    "    batchSize = s.shape[0] // BATCH_SIZE\n",
    "    \n",
    "    if batchSize == 0:\n",
    "        batchSize = 1\n",
    "                \n",
    "    targetQs = getTargetQs(initialStateMemory[s], actionMemory[s], rewardMemory[s], finalStateMemory[s], evalnet, targetnet)\n",
    "        \n",
    "    print(\"Training Model...\")\n",
    "    evalnet.fit(initialStateMemory[s],targetQs,batch_size = batchSize, epochs = epochs, verbose = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replay Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addMemory(initialState, action, reward, finalState, memCount, MAX_MEM_SIZE):\n",
    "    if memCount < MAX_MEM_SIZE:\n",
    "        initialStateMemory[memCount] = initialState.reshape(INPUT_SIZE)\n",
    "        actionMemory[memCount] = action\n",
    "        rewardMemory[memCount] = reward\n",
    "        finalStateMemory[memCount] = finalState.reshape(INPUT_SIZE)\n",
    "    else:\n",
    "        rand = np.random.randint(MAX_MEM_SIZE)\n",
    "        initialStateMemory[rand] = initialState.reshape(INPUT_SIZE)\n",
    "        actionMemory[rand] = action\n",
    "        rewardMemory[rand] = reward\n",
    "        finalStateMemory[rand] = finalState.reshape(INPUT_SIZE)\n",
    "\n",
    "    memCount += 1\n",
    "        \n",
    "    return initialStateMemory,actionMemory,rewardMemory,finalStateMemory,memCount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTargetQs(states0, actions, rewards, states1, evalnet, targetnet):\n",
    "    DISCOUNT = 0.99\n",
    "    sample_size = len(states0)\n",
    "    \n",
    "    evalnetQs = np.zeros((sample_size,4))\n",
    "    targetnetQs = np.zeros((sample_size,4))\n",
    "    currentStateQs = np.zeros((sample_size,4))\n",
    "    \n",
    "    evalnetQs = np.array([getPrediction(states1[i], evalnet) for i in range(sample_size)])\n",
    "    targetnetQs = np.array([getPrediction(states1[i], targetnet) for i in range(sample_size)])\n",
    "    currentStateQs = np.array([getPrediction(states0[i], evalnet) for i in range(sample_size)])\n",
    "    targetQs = currentStateQs\n",
    "    \n",
    "    argmaxActions = np.argmax(evalnetQs, axis = 1)\n",
    "    indices = np.arange(len(states0))\n",
    "    \n",
    "    targetQs[indices, actions] = rewards + DISCOUNT * targetnetQs[indices,argmaxActions]\n",
    "    \n",
    "    return targetQs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Game Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializeEnv():\n",
    "    env = np.zeros((BOARD_LENGTH,BOARD_LENGTH))\n",
    "\n",
    "    for i in range(2):\n",
    "        addValue(env)\n",
    "            \n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addValue(env):\n",
    "#     rand = np.random.rand()\n",
    "#     if rand > 0.1:\n",
    "#         value = 2\n",
    "#     else:\n",
    "#         value = 4\n",
    "    value = 2\n",
    "        \n",
    "    coordinate1 = random.sample(range(0,BOARD_LENGTH),1)\n",
    "    coordinate2 = random.sample(range(0,BOARD_LENGTH),1)\n",
    "        \n",
    "    if env[coordinate1,coordinate2] != 0:\n",
    "        getNewCoordinate(env,value)\n",
    "    else:\n",
    "        env[coordinate1,coordinate2] = value\n",
    "        \n",
    "    return env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNewCoordinate(env,value):\n",
    "    \n",
    "    coordinate1 = random.sample(range(0,BOARD_LENGTH),1)\n",
    "    coordinate2 = random.sample(range(0,BOARD_LENGTH),1)\n",
    "    \n",
    "    while env[coordinate1,coordinate2] != 0:\n",
    "        coordinate1 = random.sample(range(0,BOARD_LENGTH),1)\n",
    "        coordinate2 = random.sample(range(0,BOARD_LENGTH),1)\n",
    "    \n",
    "    env[coordinate1,coordinate2] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(env,action,score):\n",
    "    \n",
    "    if action == 0:\n",
    "        env, score, validAction = actionUp(env,score)\n",
    "    if action == 1:\n",
    "        env, score, validAction = actionDown(env,score)\n",
    "    if action == 2:\n",
    "        env, score, validAction = actionLeft(env,score)\n",
    "    if action == 3:\n",
    "        env, score, validAction = actionRight(env,score)\n",
    "    \n",
    "    return env, score, validAction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actionUp(env,score):\n",
    "    validAction = False\n",
    "    \n",
    "    for i in range(BOARD_LENGTH):\n",
    "        for j in range(BOARD_LENGTH):\n",
    "            row = i\n",
    "            while env[row][j] != 0 and row != 0:\n",
    "                if env[row - 1][j] != 0:\n",
    "                    if env[row - 1][j] == env[row][j]:\n",
    "                        env[row - 1][j] *= 2\n",
    "                        env[row][j] = 0\n",
    "                        score += env[row - 1][j]\n",
    "                        validAction = True\n",
    "                    break\n",
    "                temp = env[row][j]\n",
    "                env[row-1][j] = temp\n",
    "                env[row][j] = 0\n",
    "                row -= 1\n",
    "                validAction = True\n",
    "    return env, score, validAction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actionDown(env,score):\n",
    "    validAction = False\n",
    "    \n",
    "    for i in range(3,-1,-1):\n",
    "        for j in range(BOARD_LENGTH):\n",
    "            row = i\n",
    "            while env[row][j] != 0 and row != 3:\n",
    "                if env[row + 1][j] != 0:\n",
    "                    if env[row + 1][j] == env[row][j]:\n",
    "                        env[row + 1][j] *= 2\n",
    "                        env[row][j] = 0\n",
    "                        score += env[row + 1][j]\n",
    "                        validAction = True\n",
    "                    break\n",
    "                temp = env[row][j]\n",
    "                env[row + 1][j] = temp\n",
    "                env[row][j] = 0\n",
    "                row += 1\n",
    "                validAction = True\n",
    "    return env, score, validAction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actionLeft(env,score):\n",
    "    validAction = False\n",
    "    env = env.T\n",
    "    \n",
    "    for i in range(BOARD_LENGTH):\n",
    "        for j in range(BOARD_LENGTH):\n",
    "            row = i\n",
    "            while env[row][j] != 0 and row != 0:\n",
    "                if env[row - 1][j] != 0:\n",
    "                    if env[row - 1][j] == env[row][j]:\n",
    "                        env[row - 1][j] *= 2\n",
    "                        env[row][j] = 0\n",
    "                        score += env[row - 1][j]\n",
    "                        validAction = True\n",
    "                    break\n",
    "                temp = env[row][j]\n",
    "                env[row-1][j] = temp\n",
    "                env[row][j] = 0\n",
    "                row -= 1\n",
    "                validAction = True\n",
    "    env = env.T\n",
    "    return env, score, validAction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actionRight(env,score):\n",
    "    validAction = False\n",
    "    env = env.T\n",
    "    \n",
    "    for i in range(3,-1,-1):\n",
    "        for j in range(BOARD_LENGTH):\n",
    "            row = i\n",
    "            while env[row][j] != 0 and row != 3:\n",
    "                if env[row + 1][j] != 0:\n",
    "                    if env[row + 1][j] == env[row][j]:\n",
    "                        env[row + 1][j] *= 2\n",
    "                        env[row][j] = 0\n",
    "                        score += env[row + 1][j]\n",
    "                        validAction = True\n",
    "                    break\n",
    "                temp = env[row][j]\n",
    "                env[row + 1][j] = temp\n",
    "                env[row][j] = 0\n",
    "                row += 1\n",
    "                validAction = True\n",
    "    env = env.T\n",
    "    return env, score, validAction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAvailableAction(env):\n",
    "    tempEnv = np.copy(env)\n",
    "    available = False\n",
    "    \n",
    "    for i in range(tempEnv.shape[0]):\n",
    "        for j in range(tempEnv.shape[0] - 1):\n",
    "            if tempEnv[i][j] == tempEnv[i][j+1]:\n",
    "                available = True\n",
    "                \n",
    "                \n",
    "    tempEnv = tempEnv.T\n",
    "    for i in range(tempEnv.shape[0]):\n",
    "        for j in range(tempEnv.shape[0] - 1):\n",
    "            if tempEnv[i][j] == tempEnv[i][j+1]:\n",
    "                available = True\n",
    "                break\n",
    "    \n",
    "    return available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(env,agent,memCount,testFlag,score = 0):\n",
    "    \n",
    "    gameOver = False\n",
    "    while gameOver == False:\n",
    "        invalidActions = []\n",
    "        validAction = False\n",
    "        while validAction == False:\n",
    "            \n",
    "            if not testFlag:\n",
    "                previousEnv = np.copy(env)\n",
    "                previousScore = np.copy(score)\n",
    "            \n",
    "            output = getPrediction(env,agent)\n",
    "            if testFlag: \n",
    "                action = getGreedyAction(output,invalidActions) \n",
    "            else: \n",
    "                action = getAction(output,invalidActions)\n",
    "            invalidActions.append(action)\n",
    "            env, score, validAction = step(env, action, score)\n",
    "        \n",
    "        if not testFlag:\n",
    "            initialStateMemory,actionMemory,rewardMemory,finalStateMemory,memCount = addMemory(previousEnv, action, score - previousScore, env, memCount, MAX_MEM_SIZE)\n",
    "\n",
    "        env = addValue(env)\n",
    "        \n",
    "        if np.sum(env == 0) == 0:\n",
    "            gameOver = not getAvailableAction(env)\n",
    "    \n",
    "    if not testFlag:\n",
    "        return score,initialStateMemory,actionMemory,rewardMemory,finalStateMemory,memCount\n",
    "    else: \n",
    "        return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Output Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printIter():\n",
    "    print(\"\\n === === === Iteration\",iteration,\"of\",ITERATIONS,'=== === ===\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printStats(timeLog,iteration,ITERATIONS,memCount,scoreLog,greedyScoreLog,EPISODES,TESTS):\n",
    "    print(\"\\nEstimated time remaining: \", format(np.mean(timeLog) * (ITERATIONS - iteration) / 60,'.2f'),\" Minutes\\n\")\n",
    "    print(\"Memories Elapsed: \",memCount)\n",
    "    print(\"Current Epsilon: \",format(1 - EPSILON_RATE * iteration,'.4f'))\n",
    "    print(\"Ave Game Score for Epoch: \", format(np.mean(scoreLog[len(scoreLog) - EPISODES : len(scoreLog)-1]) ,'.2f'))\n",
    "    print(\"Ave Greedy Score for Epoch: \", format(np.mean(greedyScoreLog[len(greedyScoreLog) - TESTS : len(greedyScoreLog)-1]) ,'.2f'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printTrainInfo():\n",
    "    print(\"Maximum memory size:\",MAX_MEM_SIZE)\n",
    "    print(\"Sample size for training:\",SAMPLE_SIZE)\n",
    "    print(\"Batch size from sample:\",BATCH_SIZE)\n",
    "    print(\"Epslon Rate:\",format(EPSILON_RATE,'.4f'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n",
    "import sys\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.layers import Dense, Dropout, Conv2D\n",
    "\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOARD_LENGTH = 4\n",
    "INPUT_SIZE = 16\n",
    "OUTPUT_SIZE = BOARD_LENGTH\n",
    "\n",
    "memCount = 0\n",
    "MAX_MEM_SIZE = 100_000\n",
    "SAMPLE_SIZE = MAX_MEM_SIZE // 200\n",
    "BATCH_SIZE = SAMPLE_SIZE // 100\n",
    "initialStateMemory = np.zeros((MAX_MEM_SIZE,INPUT_SIZE))\n",
    "actionMemory = np.zeros(MAX_MEM_SIZE, dtype = np.int)\n",
    "rewardMemory = np.zeros(MAX_MEM_SIZE)\n",
    "finalStateMemory = np.zeros((MAX_MEM_SIZE,INPUT_SIZE))\n",
    "\n",
    "\n",
    "gameScoreLog = []\n",
    "greedyScoreLog = []\n",
    "agent = intitializeAgent()\n",
    "target = intitializeAgent()\n",
    "updateTargetNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "ITERATIONS = 100\n",
    "EPISODES = 100\n",
    "TESTS = EPISODES // 5\n",
    "EPOCHS = 4\n",
    "ITER_PER_UPDATE = 25\n",
    "MIN_EPSILON = 0.01\n",
    "EPSILON_RATE = (1 - MIN_EPSILON) / ITERATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum memory size: 100000\n",
      "Sample size for training: 500\n",
      "Batch size from sample: 5\n",
      "Epslon Rate: 0.0099\n",
      "\n",
      " === === === Iteration 0 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  22.53  Minutes\n",
      "\n",
      "Memories Elapsed:  13591\n",
      "Current Epsilon:  1.0000\n",
      "Ave Game Score for Epoch:  1222.87\n",
      "Ave Greedy Score for Epoch:  1520.00\n",
      "\n",
      " === === === Iteration 1 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  5.89  Minutes\n",
      "\n",
      "Memories Elapsed:  16901\n",
      "Current Epsilon:  0.9901\n",
      "Ave Game Score for Epoch:  1179.50\n",
      "Ave Greedy Score for Epoch:  895.00\n",
      "\n",
      " === === === Iteration 2 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  7.13  Minutes\n",
      "\n",
      "Memories Elapsed:  20733\n",
      "Current Epsilon:  0.9802\n",
      "Ave Game Score for Epoch:  1471.00\n",
      "Ave Greedy Score for Epoch:  1191.00\n",
      "\n",
      " === === === Iteration 3 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  6.73  Minutes\n",
      "\n",
      "Memories Elapsed:  24317\n",
      "Current Epsilon:  0.9703\n",
      "Ave Game Score for Epoch:  1313.50\n",
      "Ave Greedy Score for Epoch:  757.00\n",
      "\n",
      " === === === Iteration 4 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  6.51  Minutes\n",
      "\n",
      "Memories Elapsed:  28020\n",
      "Current Epsilon:  0.9604\n",
      "Ave Game Score for Epoch:  1394.33\n",
      "Ave Greedy Score for Epoch:  961.00\n",
      "\n",
      " === === === Iteration 5 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  6.28  Minutes\n",
      "\n",
      "Memories Elapsed:  31352\n",
      "Current Epsilon:  0.9505\n",
      "Ave Game Score for Epoch:  1165.17\n",
      "Ave Greedy Score for Epoch:  918.00\n",
      "\n",
      " === === === Iteration 6 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  6.16  Minutes\n",
      "\n",
      "Memories Elapsed:  34878\n",
      "Current Epsilon:  0.9406\n",
      "Ave Game Score for Epoch:  1272.17\n",
      "Ave Greedy Score for Epoch:  1414.00\n",
      "\n",
      " === === === Iteration 7 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  6.04  Minutes\n",
      "\n",
      "Memories Elapsed:  38272\n",
      "Current Epsilon:  0.9307\n",
      "Ave Game Score for Epoch:  1221.83\n",
      "Ave Greedy Score for Epoch:  1022.00\n",
      "\n",
      " === === === Iteration 8 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  5.94  Minutes\n",
      "\n",
      "Memories Elapsed:  41784\n",
      "Current Epsilon:  0.9208\n",
      "Ave Game Score for Epoch:  1316.17\n",
      "Ave Greedy Score for Epoch:  944.00\n",
      "\n",
      " === === === Iteration 9 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  5.82  Minutes\n",
      "\n",
      "Memories Elapsed:  45150\n",
      "Current Epsilon:  0.9109\n",
      "Ave Game Score for Epoch:  1163.00\n",
      "Ave Greedy Score for Epoch:  1039.00\n",
      "\n",
      " === === === Iteration 10 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  5.74  Minutes\n",
      "\n",
      "Memories Elapsed:  48676\n",
      "Current Epsilon:  0.9010\n",
      "Ave Game Score for Epoch:  1318.17\n",
      "Ave Greedy Score for Epoch:  1228.00\n",
      "\n",
      " === === === Iteration 11 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  5.67  Minutes\n",
      "\n",
      "Memories Elapsed:  52150\n",
      "Current Epsilon:  0.8911\n",
      "Ave Game Score for Epoch:  1330.00\n",
      "Ave Greedy Score for Epoch:  1384.00\n",
      "\n",
      " === === === Iteration 12 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  5.59  Minutes\n",
      "\n",
      "Memories Elapsed:  55712\n",
      "Current Epsilon:  0.8812\n",
      "Ave Game Score for Epoch:  1275.67\n",
      "Ave Greedy Score for Epoch:  858.00\n",
      "\n",
      " === === === Iteration 13 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  5.50  Minutes\n",
      "\n",
      "Memories Elapsed:  59245\n",
      "Current Epsilon:  0.8713\n",
      "Ave Game Score for Epoch:  1285.33\n",
      "Ave Greedy Score for Epoch:  1159.00\n",
      "\n",
      " === === === Iteration 14 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  5.42  Minutes\n",
      "\n",
      "Memories Elapsed:  62628\n",
      "Current Epsilon:  0.8614\n",
      "Ave Game Score for Epoch:  1205.67\n",
      "Ave Greedy Score for Epoch:  1062.00\n",
      "\n",
      " === === === Iteration 15 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  5.33  Minutes\n",
      "\n",
      "Memories Elapsed:  65944\n",
      "Current Epsilon:  0.8515\n",
      "Ave Game Score for Epoch:  1168.67\n",
      "Ave Greedy Score for Epoch:  666.00\n",
      "\n",
      " === === === Iteration 16 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  5.25  Minutes\n",
      "\n",
      "Memories Elapsed:  69280\n",
      "Current Epsilon:  0.8416\n",
      "Ave Game Score for Epoch:  1222.33\n",
      "Ave Greedy Score for Epoch:  1386.00\n",
      "\n",
      " === === === Iteration 17 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  5.16  Minutes\n",
      "\n",
      "Memories Elapsed:  72465\n",
      "Current Epsilon:  0.8317\n",
      "Ave Game Score for Epoch:  1144.83\n",
      "Ave Greedy Score for Epoch:  1507.00\n",
      "\n",
      " === === === Iteration 18 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  5.11  Minutes\n",
      "\n",
      "Memories Elapsed:  76097\n",
      "Current Epsilon:  0.8218\n",
      "Ave Game Score for Epoch:  1336.00\n",
      "Ave Greedy Score for Epoch:  1290.00\n",
      "\n",
      " === === === Iteration 19 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  5.04  Minutes\n",
      "\n",
      "Memories Elapsed:  79547\n",
      "Current Epsilon:  0.8119\n",
      "Ave Game Score for Epoch:  1245.67\n",
      "Ave Greedy Score for Epoch:  904.00\n",
      "\n",
      " === === === Iteration 20 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  4.99  Minutes\n",
      "\n",
      "Memories Elapsed:  83342\n",
      "Current Epsilon:  0.8020\n",
      "Ave Game Score for Epoch:  1423.50\n",
      "Ave Greedy Score for Epoch:  1116.00\n",
      "\n",
      " === === === Iteration 21 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  5.08  Minutes\n",
      "\n",
      "Memories Elapsed:  86828\n",
      "Current Epsilon:  0.7921\n",
      "Ave Game Score for Epoch:  1309.17\n",
      "Ave Greedy Score for Epoch:  1033.00\n",
      "\n",
      " === === === Iteration 22 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  5.13  Minutes\n",
      "\n",
      "Memories Elapsed:  90260\n",
      "Current Epsilon:  0.7822\n",
      "Ave Game Score for Epoch:  1230.17\n",
      "Ave Greedy Score for Epoch:  1361.00\n",
      "\n",
      " === === === Iteration 23 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  5.08  Minutes\n",
      "\n",
      "Memories Elapsed:  93923\n",
      "Current Epsilon:  0.7723\n",
      "Ave Game Score for Epoch:  1351.17\n",
      "Ave Greedy Score for Epoch:  951.00\n",
      "\n",
      " === === === Iteration 24 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  4.98  Minutes\n",
      "\n",
      "Memories Elapsed:  97281\n",
      "Current Epsilon:  0.7624\n",
      "Ave Game Score for Epoch:  1197.83\n",
      "Ave Greedy Score for Epoch:  893.00\n",
      "\n",
      " === === === Iteration 25 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  4.94  Minutes\n",
      "\n",
      "Memories Elapsed:  100840\n",
      "Current Epsilon:  0.7525\n",
      "Ave Game Score for Epoch:  1312.33\n",
      "Ave Greedy Score for Epoch:  1208.00\n",
      "\n",
      " === === === Iteration 26 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  4.97  Minutes\n",
      "\n",
      "Memories Elapsed:  104444\n",
      "Current Epsilon:  0.7426\n",
      "Ave Game Score for Epoch:  1338.50\n",
      "Ave Greedy Score for Epoch:  798.00\n",
      "\n",
      " === === === Iteration 27 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  4.91  Minutes\n",
      "\n",
      "Memories Elapsed:  107857\n",
      "Current Epsilon:  0.7327\n",
      "Ave Game Score for Epoch:  1242.67\n",
      "Ave Greedy Score for Epoch:  2066.00\n",
      "\n",
      " === === === Iteration 28 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  4.85  Minutes\n",
      "\n",
      "Memories Elapsed:  111791\n",
      "Current Epsilon:  0.7228\n",
      "Ave Game Score for Epoch:  1549.00\n",
      "Ave Greedy Score for Epoch:  1063.00\n",
      "\n",
      " === === === Iteration 29 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  4.78  Minutes\n",
      "\n",
      "Memories Elapsed:  115273\n",
      "Current Epsilon:  0.7129\n",
      "Ave Game Score for Epoch:  1274.00\n",
      "Ave Greedy Score for Epoch:  2185.00\n",
      "\n",
      " === === === Iteration 30 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  4.72  Minutes\n",
      "\n",
      "Memories Elapsed:  118847\n",
      "Current Epsilon:  0.7030\n",
      "Ave Game Score for Epoch:  1255.33\n",
      "Ave Greedy Score for Epoch:  2778.00\n",
      "\n",
      " === === === Iteration 31 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  4.68  Minutes\n",
      "\n",
      "Memories Elapsed:  122595\n",
      "Current Epsilon:  0.6931\n",
      "Ave Game Score for Epoch:  1451.17\n",
      "Ave Greedy Score for Epoch:  3099.00\n",
      "\n",
      " === === === Iteration 32 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  4.61  Minutes\n",
      "\n",
      "Memories Elapsed:  126239\n",
      "Current Epsilon:  0.6832\n",
      "Ave Game Score for Epoch:  1345.17\n",
      "Ave Greedy Score for Epoch:  1764.00\n",
      "\n",
      " === === === Iteration 33 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  4.55  Minutes\n",
      "\n",
      "Memories Elapsed:  129820\n",
      "Current Epsilon:  0.6733\n",
      "Ave Game Score for Epoch:  1285.00\n",
      "Ave Greedy Score for Epoch:  1133.00\n",
      "\n",
      " === === === Iteration 34 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  4.48  Minutes\n",
      "\n",
      "Memories Elapsed:  133593\n",
      "Current Epsilon:  0.6634\n",
      "Ave Game Score for Epoch:  1405.33\n",
      "Ave Greedy Score for Epoch:  1347.00\n",
      "\n",
      " === === === Iteration 35 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  4.39  Minutes\n",
      "\n",
      "Memories Elapsed:  136942\n",
      "Current Epsilon:  0.6535\n",
      "Ave Game Score for Epoch:  1266.00\n",
      "Ave Greedy Score for Epoch:  721.00\n",
      "\n",
      " === === === Iteration 36 of 100 === === ===\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  4.32  Minutes\n",
      "\n",
      "Memories Elapsed:  140441\n",
      "Current Epsilon:  0.6436\n",
      "Ave Game Score for Epoch:  1213.50\n",
      "Ave Greedy Score for Epoch:  2109.00\n",
      "\n",
      " === === === Iteration 37 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  4.25  Minutes\n",
      "\n",
      "Memories Elapsed:  144107\n",
      "Current Epsilon:  0.6337\n",
      "Ave Game Score for Epoch:  1336.00\n",
      "Ave Greedy Score for Epoch:  1402.00\n",
      "\n",
      " === === === Iteration 38 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  4.19  Minutes\n",
      "\n",
      "Memories Elapsed:  147410\n",
      "Current Epsilon:  0.6238\n",
      "Ave Game Score for Epoch:  1165.33\n",
      "Ave Greedy Score for Epoch:  861.00\n",
      "\n",
      " === === === Iteration 39 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  4.13  Minutes\n",
      "\n",
      "Memories Elapsed:  151283\n",
      "Current Epsilon:  0.6139\n",
      "Ave Game Score for Epoch:  1415.33\n",
      "Ave Greedy Score for Epoch:  1736.00\n",
      "\n",
      " === === === Iteration 40 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  4.06  Minutes\n",
      "\n",
      "Memories Elapsed:  154786\n",
      "Current Epsilon:  0.6040\n",
      "Ave Game Score for Epoch:  1286.00\n",
      "Ave Greedy Score for Epoch:  2291.00\n",
      "\n",
      " === === === Iteration 41 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  3.99  Minutes\n",
      "\n",
      "Memories Elapsed:  158288\n",
      "Current Epsilon:  0.5941\n",
      "Ave Game Score for Epoch:  1226.33\n",
      "Ave Greedy Score for Epoch:  1021.00\n",
      "\n",
      " === === === Iteration 42 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  3.91  Minutes\n",
      "\n",
      "Memories Elapsed:  161543\n",
      "Current Epsilon:  0.5842\n",
      "Ave Game Score for Epoch:  1160.33\n",
      "Ave Greedy Score for Epoch:  858.00\n",
      "\n",
      " === === === Iteration 43 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  3.84  Minutes\n",
      "\n",
      "Memories Elapsed:  164744\n",
      "Current Epsilon:  0.5743\n",
      "Ave Game Score for Epoch:  1100.17\n",
      "Ave Greedy Score for Epoch:  1232.00\n",
      "\n",
      " === === === Iteration 44 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  3.78  Minutes\n",
      "\n",
      "Memories Elapsed:  168132\n",
      "Current Epsilon:  0.5644\n",
      "Ave Game Score for Epoch:  1198.33\n",
      "Ave Greedy Score for Epoch:  2155.00\n",
      "\n",
      " === === === Iteration 45 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  3.73  Minutes\n",
      "\n",
      "Memories Elapsed:  171672\n",
      "Current Epsilon:  0.5545\n",
      "Ave Game Score for Epoch:  1298.67\n",
      "Ave Greedy Score for Epoch:  2330.00\n",
      "\n",
      " === === === Iteration 46 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  3.67  Minutes\n",
      "\n",
      "Memories Elapsed:  175000\n",
      "Current Epsilon:  0.5446\n",
      "Ave Game Score for Epoch:  1155.33\n",
      "Ave Greedy Score for Epoch:  1490.00\n",
      "\n",
      " === === === Iteration 47 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  3.63  Minutes\n",
      "\n",
      "Memories Elapsed:  178246\n",
      "Current Epsilon:  0.5347\n",
      "Ave Game Score for Epoch:  1098.17\n",
      "Ave Greedy Score for Epoch:  3167.00\n",
      "\n",
      " === === === Iteration 48 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  3.57  Minutes\n",
      "\n",
      "Memories Elapsed:  181774\n",
      "Current Epsilon:  0.5248\n",
      "Ave Game Score for Epoch:  1274.33\n",
      "Ave Greedy Score for Epoch:  2439.00\n",
      "\n",
      " === === === Iteration 49 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  3.52  Minutes\n",
      "\n",
      "Memories Elapsed:  185331\n",
      "Current Epsilon:  0.5149\n",
      "Ave Game Score for Epoch:  1265.50\n",
      "Ave Greedy Score for Epoch:  1048.00\n",
      "\n",
      " === === === Iteration 50 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  3.46  Minutes\n",
      "\n",
      "Memories Elapsed:  188514\n",
      "Current Epsilon:  0.5050\n",
      "Ave Game Score for Epoch:  1127.83\n",
      "Ave Greedy Score for Epoch:  2329.00\n",
      "\n",
      " === === === Iteration 51 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  3.40  Minutes\n",
      "\n",
      "Memories Elapsed:  191883\n",
      "Current Epsilon:  0.4951\n",
      "Ave Game Score for Epoch:  1191.83\n",
      "Ave Greedy Score for Epoch:  1624.00\n",
      "\n",
      " === === === Iteration 52 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  3.33  Minutes\n",
      "\n",
      "Memories Elapsed:  195131\n",
      "Current Epsilon:  0.4852\n",
      "Ave Game Score for Epoch:  1122.67\n",
      "Ave Greedy Score for Epoch:  2206.00\n",
      "\n",
      " === === === Iteration 53 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  3.28  Minutes\n",
      "\n",
      "Memories Elapsed:  198981\n",
      "Current Epsilon:  0.4753\n",
      "Ave Game Score for Epoch:  1460.50\n",
      "Ave Greedy Score for Epoch:  3194.00\n",
      "\n",
      " === === === Iteration 54 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  3.21  Minutes\n",
      "\n",
      "Memories Elapsed:  202645\n",
      "Current Epsilon:  0.4654\n",
      "Ave Game Score for Epoch:  1366.50\n",
      "Ave Greedy Score for Epoch:  1819.00\n",
      "\n",
      " === === === Iteration 55 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  3.16  Minutes\n",
      "\n",
      "Memories Elapsed:  206639\n",
      "Current Epsilon:  0.4555\n",
      "Ave Game Score for Epoch:  1564.83\n",
      "Ave Greedy Score for Epoch:  2076.00\n",
      "\n",
      " === === === Iteration 56 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  3.09  Minutes\n",
      "\n",
      "Memories Elapsed:  210163\n",
      "Current Epsilon:  0.4456\n",
      "Ave Game Score for Epoch:  1233.83\n",
      "Ave Greedy Score for Epoch:  2531.00\n",
      "\n",
      " === === === Iteration 57 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  3.03  Minutes\n",
      "\n",
      "Memories Elapsed:  214069\n",
      "Current Epsilon:  0.4357\n",
      "Ave Game Score for Epoch:  1497.67\n",
      "Ave Greedy Score for Epoch:  2889.00\n",
      "\n",
      " === === === Iteration 58 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  2.96  Minutes\n",
      "\n",
      "Memories Elapsed:  217943\n",
      "Current Epsilon:  0.4258\n",
      "Ave Game Score for Epoch:  1475.33\n",
      "Ave Greedy Score for Epoch:  1355.00\n",
      "\n",
      " === === === Iteration 59 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  2.89  Minutes\n",
      "\n",
      "Memories Elapsed:  221300\n",
      "Current Epsilon:  0.4159\n",
      "Ave Game Score for Epoch:  1152.33\n",
      "Ave Greedy Score for Epoch:  1683.00\n",
      "\n",
      " === === === Iteration 60 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  2.82  Minutes\n",
      "\n",
      "Memories Elapsed:  224464\n",
      "Current Epsilon:  0.4060\n",
      "Ave Game Score for Epoch:  1079.67\n",
      "Ave Greedy Score for Epoch:  3089.00\n",
      "\n",
      " === === === Iteration 61 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  2.75  Minutes\n",
      "\n",
      "Memories Elapsed:  227653\n",
      "Current Epsilon:  0.3961\n",
      "Ave Game Score for Epoch:  1074.00\n",
      "Ave Greedy Score for Epoch:  2049.00\n",
      "\n",
      " === === === Iteration 62 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  2.72  Minutes\n",
      "\n",
      "Memories Elapsed:  231069\n",
      "Current Epsilon:  0.3862\n",
      "Ave Game Score for Epoch:  1237.17\n",
      "Ave Greedy Score for Epoch:  3062.00\n",
      "\n",
      " === === === Iteration 63 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  2.69  Minutes\n",
      "\n",
      "Memories Elapsed:  234667\n",
      "Current Epsilon:  0.3763\n",
      "Ave Game Score for Epoch:  1314.67\n",
      "Ave Greedy Score for Epoch:  2588.00\n",
      "\n",
      " === === === Iteration 64 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  2.63  Minutes\n",
      "\n",
      "Memories Elapsed:  238433\n",
      "Current Epsilon:  0.3664\n",
      "Ave Game Score for Epoch:  1386.33\n",
      "Ave Greedy Score for Epoch:  1678.00\n",
      "\n",
      " === === === Iteration 65 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  2.57  Minutes\n",
      "\n",
      "Memories Elapsed:  242296\n",
      "Current Epsilon:  0.3565\n",
      "Ave Game Score for Epoch:  1437.33\n",
      "Ave Greedy Score for Epoch:  3012.00\n",
      "\n",
      " === === === Iteration 66 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  2.50  Minutes\n",
      "\n",
      "Memories Elapsed:  245773\n",
      "Current Epsilon:  0.3466\n",
      "Ave Game Score for Epoch:  1244.83\n",
      "Ave Greedy Score for Epoch:  1985.00\n",
      "\n",
      " === === === Iteration 67 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  2.44  Minutes\n",
      "\n",
      "Memories Elapsed:  249499\n",
      "Current Epsilon:  0.3367\n",
      "Ave Game Score for Epoch:  1346.00\n",
      "Ave Greedy Score for Epoch:  2786.00\n",
      "\n",
      " === === === Iteration 68 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  2.38  Minutes\n",
      "\n",
      "Memories Elapsed:  253044\n",
      "Current Epsilon:  0.3268\n",
      "Ave Game Score for Epoch:  1277.00\n",
      "Ave Greedy Score for Epoch:  3145.00\n",
      "\n",
      " === === === Iteration 69 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  2.30  Minutes\n",
      "\n",
      "Memories Elapsed:  256910\n",
      "Current Epsilon:  0.3169\n",
      "Ave Game Score for Epoch:  1489.67\n",
      "Ave Greedy Score for Epoch:  2664.00\n",
      "\n",
      " === === === Iteration 70 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  2.23  Minutes\n",
      "\n",
      "Memories Elapsed:  260904\n",
      "Current Epsilon:  0.3070\n",
      "Ave Game Score for Epoch:  1514.67\n",
      "Ave Greedy Score for Epoch:  2291.00\n",
      "\n",
      " === === === Iteration 71 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  2.16  Minutes\n",
      "\n",
      "Memories Elapsed:  264528\n",
      "Current Epsilon:  0.2971\n",
      "Ave Game Score for Epoch:  1324.33\n",
      "Ave Greedy Score for Epoch:  2796.00\n",
      "\n",
      " === === === Iteration 72 of 100 === === ===\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  2.10  Minutes\n",
      "\n",
      "Memories Elapsed:  268368\n",
      "Current Epsilon:  0.2872\n",
      "Ave Game Score for Epoch:  1365.67\n",
      "Ave Greedy Score for Epoch:  3776.00\n",
      "\n",
      " === === === Iteration 73 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  2.03  Minutes\n",
      "\n",
      "Memories Elapsed:  272648\n",
      "Current Epsilon:  0.2773\n",
      "Ave Game Score for Epoch:  1711.00\n",
      "Ave Greedy Score for Epoch:  1951.00\n",
      "\n",
      " === === === Iteration 74 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  1.95  Minutes\n",
      "\n",
      "Memories Elapsed:  276448\n",
      "Current Epsilon:  0.2674\n",
      "Ave Game Score for Epoch:  1359.33\n",
      "Ave Greedy Score for Epoch:  3130.00\n",
      "\n",
      " === === === Iteration 75 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  1.88  Minutes\n",
      "\n",
      "Memories Elapsed:  280124\n",
      "Current Epsilon:  0.2575\n",
      "Ave Game Score for Epoch:  1355.67\n",
      "Ave Greedy Score for Epoch:  3789.00\n",
      "\n",
      " === === === Iteration 76 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  1.81  Minutes\n",
      "\n",
      "Memories Elapsed:  284304\n",
      "Current Epsilon:  0.2476\n",
      "Ave Game Score for Epoch:  1621.00\n",
      "Ave Greedy Score for Epoch:  1723.00\n",
      "\n",
      " === === === Iteration 77 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  1.73  Minutes\n",
      "\n",
      "Memories Elapsed:  288214\n",
      "Current Epsilon:  0.2377\n",
      "Ave Game Score for Epoch:  1445.33\n",
      "Ave Greedy Score for Epoch:  1977.00\n",
      "\n",
      " === === === Iteration 78 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  1.66  Minutes\n",
      "\n",
      "Memories Elapsed:  291739\n",
      "Current Epsilon:  0.2278\n",
      "Ave Game Score for Epoch:  1240.33\n",
      "Ave Greedy Score for Epoch:  3596.00\n",
      "\n",
      " === === === Iteration 79 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  1.59  Minutes\n",
      "\n",
      "Memories Elapsed:  295619\n",
      "Current Epsilon:  0.2179\n",
      "Ave Game Score for Epoch:  1425.17\n",
      "Ave Greedy Score for Epoch:  2346.00\n",
      "\n",
      " === === === Iteration 80 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  1.52  Minutes\n",
      "\n",
      "Memories Elapsed:  299237\n",
      "Current Epsilon:  0.2080\n",
      "Ave Game Score for Epoch:  1340.50\n",
      "Ave Greedy Score for Epoch:  1928.00\n",
      "\n",
      " === === === Iteration 81 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  1.44  Minutes\n",
      "\n",
      "Memories Elapsed:  303230\n",
      "Current Epsilon:  0.1981\n",
      "Ave Game Score for Epoch:  1504.83\n",
      "Ave Greedy Score for Epoch:  2196.00\n",
      "\n",
      " === === === Iteration 82 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  1.37  Minutes\n",
      "\n",
      "Memories Elapsed:  307432\n",
      "Current Epsilon:  0.1882\n",
      "Ave Game Score for Epoch:  1617.17\n",
      "Ave Greedy Score for Epoch:  3328.00\n",
      "\n",
      " === === === Iteration 83 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  1.29  Minutes\n",
      "\n",
      "Memories Elapsed:  311875\n",
      "Current Epsilon:  0.1783\n",
      "Ave Game Score for Epoch:  1702.67\n",
      "Ave Greedy Score for Epoch:  2242.00\n",
      "\n",
      " === === === Iteration 84 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  1.22  Minutes\n",
      "\n",
      "Memories Elapsed:  316081\n",
      "Current Epsilon:  0.1684\n",
      "Ave Game Score for Epoch:  1636.00\n",
      "Ave Greedy Score for Epoch:  2526.00\n",
      "\n",
      " === === === Iteration 85 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  1.15  Minutes\n",
      "\n",
      "Memories Elapsed:  320236\n",
      "Current Epsilon:  0.1585\n",
      "Ave Game Score for Epoch:  1528.33\n",
      "Ave Greedy Score for Epoch:  3207.00\n",
      "\n",
      " === === === Iteration 86 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  1.07  Minutes\n",
      "\n",
      "Memories Elapsed:  323984\n",
      "Current Epsilon:  0.1486\n",
      "Ave Game Score for Epoch:  1367.00\n",
      "Ave Greedy Score for Epoch:  2991.00\n",
      "\n",
      " === === === Iteration 87 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  1.00  Minutes\n",
      "\n",
      "Memories Elapsed:  328797\n",
      "Current Epsilon:  0.1387\n",
      "Ave Game Score for Epoch:  1973.50\n",
      "Ave Greedy Score for Epoch:  3363.00\n",
      "\n",
      " === === === Iteration 88 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  0.92  Minutes\n",
      "\n",
      "Memories Elapsed:  333095\n",
      "Current Epsilon:  0.1288\n",
      "Ave Game Score for Epoch:  1636.83\n",
      "Ave Greedy Score for Epoch:  3330.00\n",
      "\n",
      " === === === Iteration 89 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  0.85  Minutes\n",
      "\n",
      "Memories Elapsed:  337637\n",
      "Current Epsilon:  0.1189\n",
      "Ave Game Score for Epoch:  1759.50\n",
      "Ave Greedy Score for Epoch:  1713.00\n",
      "\n",
      " === === === Iteration 90 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  0.77  Minutes\n",
      "\n",
      "Memories Elapsed:  341810\n",
      "Current Epsilon:  0.1090\n",
      "Ave Game Score for Epoch:  1598.00\n",
      "Ave Greedy Score for Epoch:  2308.00\n",
      "\n",
      " === === === Iteration 91 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  0.69  Minutes\n",
      "\n",
      "Memories Elapsed:  346449\n",
      "Current Epsilon:  0.0991\n",
      "Ave Game Score for Epoch:  1881.50\n",
      "Ave Greedy Score for Epoch:  2807.00\n",
      "\n",
      " === === === Iteration 92 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  0.62  Minutes\n",
      "\n",
      "Memories Elapsed:  350932\n",
      "Current Epsilon:  0.0892\n",
      "Ave Game Score for Epoch:  1728.83\n",
      "Ave Greedy Score for Epoch:  2221.00\n",
      "\n",
      " === === === Iteration 93 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  0.54  Minutes\n",
      "\n",
      "Memories Elapsed:  355512\n",
      "Current Epsilon:  0.0793\n",
      "Ave Game Score for Epoch:  1852.83\n",
      "Ave Greedy Score for Epoch:  2205.00\n",
      "\n",
      " === === === Iteration 94 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  0.46  Minutes\n",
      "\n",
      "Memories Elapsed:  360990\n",
      "Current Epsilon:  0.0694\n",
      "Ave Game Score for Epoch:  2287.83\n",
      "Ave Greedy Score for Epoch:  3690.00\n",
      "\n",
      " === === === Iteration 95 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  0.39  Minutes\n",
      "\n",
      "Memories Elapsed:  366295\n",
      "Current Epsilon:  0.0595\n",
      "Ave Game Score for Epoch:  2254.67\n",
      "Ave Greedy Score for Epoch:  2751.00\n",
      "\n",
      " === === === Iteration 96 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  0.31  Minutes\n",
      "\n",
      "Memories Elapsed:  371058\n",
      "Current Epsilon:  0.0496\n",
      "Ave Game Score for Epoch:  1944.00\n",
      "Ave Greedy Score for Epoch:  2223.00\n",
      "\n",
      " === === === Iteration 97 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  0.23  Minutes\n",
      "\n",
      "Memories Elapsed:  375618\n",
      "Current Epsilon:  0.0397\n",
      "Ave Game Score for Epoch:  1722.50\n",
      "Ave Greedy Score for Epoch:  2952.00\n",
      "\n",
      " === === === Iteration 98 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  0.16  Minutes\n",
      "\n",
      "Memories Elapsed:  380738\n",
      "Current Epsilon:  0.0298\n",
      "Ave Game Score for Epoch:  2065.50\n",
      "Ave Greedy Score for Epoch:  2225.00\n",
      "\n",
      " === === === Iteration 99 of 100 === === ===\n",
      "\n",
      "Training Model...\n",
      "\n",
      "Estimated time remaining:  0.08  Minutes\n",
      "\n",
      "Memories Elapsed:  386747\n",
      "Current Epsilon:  0.0199\n",
      "Ave Game Score for Epoch:  2518.83\n",
      "Ave Greedy Score for Epoch:  3112.00\n"
     ]
    }
   ],
   "source": [
    "startTime = time.time()\n",
    "timeLog = []\n",
    "\n",
    "printTrainInfo()\n",
    "\n",
    "for iteration in range(ITERATIONS):\n",
    "    printIter()\n",
    "    iterationStart = time.time()\n",
    "    \n",
    "    for i in range(EPISODES):\n",
    "        score,initialStateMemory,actionMemory,rewardMemory,finalStateMemory,memCount = run(initializeEnv(),agent,memCount,False)\n",
    "        gameScoreLog.append(score)\n",
    "    \n",
    "    for i in range(TESTS):\n",
    "        score = run(initializeEnv(),agent,memCount,True)\n",
    "        greedyScoreLog.append(score)\n",
    "        \n",
    "    train(initialStateMemory,actionMemory,rewardMemory,finalStateMemory,agent,target,EPOCHS)\n",
    "    timeLog.append(time.time() - iterationStart)\n",
    "    \n",
    "    if iteration % iter_per_update == 0:\n",
    "        updateTargetNetwork()\n",
    "    \n",
    "    printStats(timeLog,iteration,ITERATIONS,memCount,gameScoreLog,greedyScoreLog,EPISODES,TESTS)\n",
    "    \n",
    "    if EPISODES != 25:\n",
    "        startTime = time.time()\n",
    "        timeLog = []\n",
    "        gameScoreLog = []\n",
    "        greedyScoreLog = []\n",
    "    \n",
    "    EPISODES = 25\n",
    "    TESTS = EPISODES // 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def getMovingAve(movingAveSize, scores):\n",
    "    movingAve = []\n",
    "    \n",
    "    for i in range(len(scores) // movingAveSize):\n",
    "        if (i + 1) * movingAveSize < len(scores):\n",
    "            movingAve.append(np.mean(scores[i*movingAveSize:(i+1)*movingAveSize]))\n",
    "    return movingAve\n",
    "\n",
    "\n",
    "def mapScores():\n",
    "    movingAveSize = 5\n",
    "    \n",
    "    movingAveA = getMovingAve(movingAveSize*5, gameScoreLog)\n",
    "    movingAveB = getMovingAve(movingAveSize, greedyScoreLog)\n",
    "    \n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.scatter(np.arange(len(movingAveA)),movingAveA)\n",
    "    plt.scatter(np.arange(len(movingAveB)),movingAveB)\n",
    "    \n",
    "mapScores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Score:  2636.08\n",
      "Std Deviation:  1255.58\n",
      "Time elapsed:   557.75\n"
     ]
    }
   ],
   "source": [
    "def testAgent():\n",
    "    games = 500\n",
    "    \n",
    "    scores = np.zeros(games)\n",
    "    \n",
    "    for i in range(games):\n",
    "        scores[i] = (run(initializeEnv(),agent,memCount,True))\n",
    "    \n",
    "    print(\"Average Score: \", np.mean(scores))\n",
    "    print(\"Std Deviation: \", format(np.std(scores),'.2f'))\n",
    "    print(\"Time elapsed:  \", format(time.time() - startTime, '.2f'))\n",
    "    \n",
    "\n",
    "testAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
